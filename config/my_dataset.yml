dataset:
  path: data/your_data.parquet   # or .csv
  format: parquet                # csv|parquet
  target: Y
  sensitive: S                   # set to null if not applicable
  partitions:
    X: [age, education_num, income_hist]   # parents/observables
    Z: [region, year]                       # exogenous/observed
    W: [gpa, bmi, hours_studied]            # mediators to model with flows
  immutable: [sex, race]         # hard constraints
  actionable:
    gpa:   {type: continuous, min: 0, max: 4,   step: 0.01, cost_per_unit: 3.0}
    bmi:   {type: continuous, min: 12, max: 50, step: 0.1,  cost_per_unit: 1.0}
    hours_studied: {type: integer, min: 0, max: 100, step: 1, cost_per_unit: 0.3}
  encodings:
    categorical: [region, year, sex, race, education_num]
    continuous:  [age, gpa, bmi, hours_studied, income_hist]
  standardize: [age, gpa, bmi, hours_studied, income_hist]
  train_valid_test: [0.7, 0.15, 0.15]

model:
  type: nsf                      # nsf|realnvp
  hidden_features: 128
  num_transforms: 8
  num_bins: 8
  dropout: 0.0
  lr: 1e-3
  batch_size: 512
  epochs: 50
  early_stop_patience: 5
  seed: 42
  condition_on: [X, Z]           # what to condition the flow on

recourse:
  # how we build counterfactuals x' = (X,Z,W') with sampled W'
  k_samples_per_x: 128
  classifier_path: models/f_hat.pt   # your predictive model f
  accept_if_prob_above: 0.5
  max_iter_project: 3                # projection to constraints
  topk_return: 5
  ite_estimator: none                # none|xl|dml (optional)

fairness:
  group: S                           # evaluate by sensitive attribute
  metrics:
    - recourse_success_rate
    - avg_cost
    - success_cost_curve
    - wasserstein_cost_gap
